<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Delta Operational Metrics Store (DeltaOMS)</title><link>https://databrickslabs.github.io/delta-oms/</link><description>Recent content on Delta Operational Metrics Store (DeltaOMS)</description><generator>Hugo -- gohugo.io</generator><lastBuildDate>Wed, 04 Aug 2021 14:50:11 -0400</lastBuildDate><atom:link href="https://databrickslabs.github.io/delta-oms/index.xml" rel="self" type="application/rss+xml"/><item><title>General</title><link>https://databrickslabs.github.io/delta-oms/faq/general/</link><pubDate>Wed, 04 Aug 2021 14:50:11 -0400</pubDate><guid>https://databrickslabs.github.io/delta-oms/faq/general/</guid><description>Q. What is Delta Operational Metrics Store ?
Delta Operational metrics store (DeltaOMS) is a solution/framework for automated collection and tracking of Delta commit logs and other future operational metrics from Delta Lake, build a centralized repository for Delta Lake operational statistics and simplify analysis across the entire data lake.
The solution can be easily enabled and configured to start capturing the operational metrics into a centralized repository on the data lake.</description></item><item><title>Configuration Tables</title><link>https://databrickslabs.github.io/delta-oms/developer_guide/configurationtables/</link><pubDate>Wed, 04 Aug 2021 14:27:39 -0400</pubDate><guid>https://databrickslabs.github.io/delta-oms/developer_guide/configurationtables/</guid><description>Source Config Default Name : sourceconfig
Table used for adding databases/paths/individual table to be tracked by DeltaOMS
Column Type Description path String Path to the Delta object to be tracked by DeltaOMS. Could be a database (all tables will be included), directory, individual table or specific path skipProcessing Boolean Flag to exclude processing a row parameters Map&amp;lt;String,String&amp;gt; Placeholder for dynamic parameters to be passed to DeltaOMS (supports easy future expansion).</description></item><item><title>Data Tables</title><link>https://databrickslabs.github.io/delta-oms/developer_guide/datatables/</link><pubDate>Wed, 04 Aug 2021 14:27:39 -0400</pubDate><guid>https://databrickslabs.github.io/delta-oms/developer_guide/datatables/</guid><description>Raw Actions Default Name : rawactions
Stores the raw actions captured through the ingestion of the _delta_log json files for all tracked tables. The schema has the columns matching the Actions from here(https://github.com/delta-io/delta/blob/master/core/src/main/scala/org/apache/spark/sql/delta/actions/actions.scala#L515) and the Delta Log Protocol with the following additional fields :
Column Type Description file_name String Name of the Delta log transaction json file. Eg. - dbfs:/user/hive/warehouse/sample.db/table1/_delta_log/00000000000000000025.json path String Path to the Delta table.</description></item><item><title>Execution</title><link>https://databrickslabs.github.io/delta-oms/faq/execution/</link><pubDate>Wed, 04 Aug 2021 14:26:55 -0400</pubDate><guid>https://databrickslabs.github.io/delta-oms/faq/execution/</guid><description>Q. How do I get started ?
Please refer to the Getting Started guide
Q. How do I add databases to be monitored by DeltaOMS ?
You can add a database name to the DeltaOMS configuration table (by default called sourceconfig) using simple SQL INSERT statement.
Example:
INSERT INTO &amp;lt;omsDBName&amp;gt;.sourceconfig VALUES('&amp;lt;Database Name&amp;gt;',false, Map('wildCardLevel','0'))
For more details on the configurations and parameters, refer to Getting Started and Developer Guide
Q. What components will to be deployed for DeltaOMS ?</description></item><item><title>Pre-Requisites</title><link>https://databrickslabs.github.io/delta-oms/getting_started/prerequisites/</link><pubDate>Wed, 04 Aug 2021 14:25:26 -0400</pubDate><guid>https://databrickslabs.github.io/delta-oms/getting_started/prerequisites/</guid><description>Make sure you have the following available before proceeding :
Access to Databricks environment with access to Delta tables/databases Ability to create Databricks job and run them on new cluster Proper access permissions to create database, tables and write data to the desired OMS location Access to create libraries on your Databricks environment. Required to attach the relevant DeltaOMS (delta-oms) libraries (Optional) Able to access the DeltaOMS github repo for demo notebooks and scripts Databricks Runtime 11.</description></item><item><title>Data Model</title><link>https://databrickslabs.github.io/delta-oms/developer_guide/datamodels/</link><pubDate>Wed, 04 Aug 2021 14:27:39 -0400</pubDate><guid>https://databrickslabs.github.io/delta-oms/developer_guide/datamodels/</guid><description>DeltaOMS collects and processes the operational metrics provided by Databricks Delta operations
DeltaOMS centralizes and organizes the data according to the following Data Model.</description></item><item><title>Security</title><link>https://databrickslabs.github.io/delta-oms/faq/security/</link><pubDate>Wed, 04 Aug 2021 14:26:55 -0400</pubDate><guid>https://databrickslabs.github.io/delta-oms/faq/security/</guid><description>Q. Would I need to give permissions to all my data for this solution to work ?
DeltaOMS processes the Delta transaction logs implementing the Delta protocol to capture the different operational metrics. These logs are stored under the folder _delta_log alongside your data files. DeltaOMS only requires access to this _delta_log folder for the tracked data locations.
For more details on how DeltaOMS works please refer to the Developer Guide</description></item><item><title>Setup</title><link>https://databrickslabs.github.io/delta-oms/getting_started/setup/</link><pubDate>Wed, 04 Aug 2021 14:25:26 -0400</pubDate><guid>https://databrickslabs.github.io/delta-oms/getting_started/setup/</guid><description>Initialize the DeltaOMS Database DeltaOMS can be configured through multiple methods :
Command line parameters - Limited to few configurations Spark configurations - All configurations.Refer to Additional Configurations section below for full details Command Line Parameters over-rides Spark Configurations.
For this tutorial we will use the command line parameters.More details about the other configurations can be found under Additional Configurations section.
Follow the below steps to initialize the DeltaOMS centralized Database and tables.</description></item><item><title>Key Components</title><link>https://databrickslabs.github.io/delta-oms/developer_guide/components/</link><pubDate>Wed, 04 Aug 2021 14:27:39 -0400</pubDate><guid>https://databrickslabs.github.io/delta-oms/developer_guide/components/</guid><description>Initialization DeltaOMS provides the component com.databricks.labs.deltaoms.init.InitializeOMS for initializing
the centralized OMS database. The component creates the OMS DB at the location specified by the configuration settings. Note: This process will delete all existing data in the specified location.
Refer to Additional Configurations for full configuration settings.
Configuration Once DeltaOMS has been initialized, and the input sources configured Source Config, the component provided by com.databricks.labs.deltaoms.init.ConfigurePaths is executed to populate the internal path config tables.</description></item><item><title>Execute</title><link>https://databrickslabs.github.io/delta-oms/getting_started/execute/</link><pubDate>Wed, 04 Aug 2021 14:25:26 -0400</pubDate><guid>https://databrickslabs.github.io/delta-oms/getting_started/execute/</guid><description>Execute the DeltaOMS Jobs You can run the jobs created in the above step to ingest and process the delta transaction information for the configured tables into the centralized DeltaOMS database.
For example, the OMSIngestion_* job(s) bring in the raw delta logs from the configured databases/tables and the OMSProcessing_* job processes the raw delta logs to format and enrich them for analytics.
For more advanced details on the working of these jobs please refer to the Developer Guide</description></item><item><title>Analyze</title><link>https://databrickslabs.github.io/delta-oms/getting_started/analyze/</link><pubDate>Wed, 04 Aug 2021 14:25:26 -0400</pubDate><guid>https://databrickslabs.github.io/delta-oms/getting_started/analyze/</guid><description>Run analytics using sample notebooks You can run some sample analytics on the data from the OMS database using the provided notebook
Modify the queries to reflect your configuration for OMS DB Name and other table names (if applicable).
Executing this notebook will give you an idea on the type of analysis and data structure that can be utilized as part of the DeltaOMS.
You can build on top of this notebook , customize this notebook to your liking and create your own Analytics insights and dashboards through Databricks notebooks and/or SQL Analytics.</description></item><item><title>Additional Configuration</title><link>https://databrickslabs.github.io/delta-oms/getting_started/additionalconfigurations/</link><pubDate>Wed, 04 Aug 2021 14:25:26 -0400</pubDate><guid>https://databrickslabs.github.io/delta-oms/getting_started/additionalconfigurations/</guid><description>Spark Configuration DeltaOMS uses multiple Spark configurations to control its different components.
DeltaOMS Spark configuration (spark.conf) details :
Configuration Key Description Required Example Default Value Applies to components databricks.labs.deltaoms.base.location Base location/path of the OMS Database on the Delta Lake Y dbfs:/spark-warehouse/oms.db, /tmp/spark-warehouse/oms.db None All databricks.labs.deltaoms.db.name OMS Database Name. This is the database where all the Delta log details will be collected Y oms.</description></item></channel></rss>
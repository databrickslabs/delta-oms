<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Delta Operational Metrics Store (DeltaOMS)</title>
    <link>https://databrickslabs.github.io/delta-oms/</link>
    <description>Recent content on Delta Operational Metrics Store (DeltaOMS)</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Wed, 04 Aug 2021 14:50:11 -0400</lastBuildDate><atom:link href="https://databrickslabs.github.io/delta-oms/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>General</title>
      <link>https://databrickslabs.github.io/delta-oms/faq/general/</link>
      <pubDate>Wed, 04 Aug 2021 14:50:11 -0400</pubDate>
      
      <guid>https://databrickslabs.github.io/delta-oms/faq/general/</guid>
      <description>Q. What is Delta Operational Metrics Store ?
Delta Operational metrics store (DeltaOMS) is a solution/framework for automated collection and tracking of Delta commit/transaction logs and associated operational metrics from Delta Lake, build a centralized repository for Delta Lake operational statistics and simplify analysis across the entire data lake.
The solution can be easily enabled and configured to start capturing the operational metrics into a centralized repository on the data lake.</description>
    </item>
    
    <item>
      <title>Configuration Tables</title>
      <link>https://databrickslabs.github.io/delta-oms/developer_guide/configurationtables/</link>
      <pubDate>Wed, 04 Aug 2021 14:27:39 -0400</pubDate>
      
      <guid>https://databrickslabs.github.io/delta-oms/developer_guide/configurationtables/</guid>
      <description>Source Config Default Name : sourceconfig
Table used for adding databases/paths/individual table to be tracked by DeltaOMS
Column Type Description path String Path to the Delta object to be tracked by DeltaOMS. Could be a database (all tables will be included), directory, individual table or specific path skipProcessing Boolean Flag to exclude processing a row Typical usage for adding input source configuration :
-- Adding a Catalog or Catalogs by Pattern INSERT INTO &amp;lt;OMSCATALOGNAME&amp;gt;.</description>
    </item>
    
    <item>
      <title>Data Tables</title>
      <link>https://databrickslabs.github.io/delta-oms/developer_guide/datatables/</link>
      <pubDate>Wed, 04 Aug 2021 14:27:39 -0400</pubDate>
      
      <guid>https://databrickslabs.github.io/delta-oms/developer_guide/datatables/</guid>
      <description>Raw Actions Default Name : rawactions
Stores the raw actions captured through the ingestion of the _delta_log json files for all tracked tables. The schema has the columns matching the Actions from here(https://github.com/delta-io/delta/blob/master/core/src/main/scala/org/apache/spark/sql/delta/actions/actions.scala#L515) and the Delta Log Protocol with the following additional fields :
Column Type Description file_name String Name of the Delta log transaction json file. Eg. - dbfs:/user/hive/warehouse/sample.db/table1/_delta_log/00000000000000000025.json path String Path to the Delta table. Eg. - dbfs:/user/hive/warehouse/sample.db/table1 puid String Path Unique Identifier (Partition column) commit_version Long Transaction Commit Version of the data.</description>
    </item>
    
    <item>
      <title>Execution</title>
      <link>https://databrickslabs.github.io/delta-oms/faq/execution/</link>
      <pubDate>Wed, 04 Aug 2021 14:26:55 -0400</pubDate>
      
      <guid>https://databrickslabs.github.io/delta-oms/faq/execution/</guid>
      <description>Q. How do I get started ?
Please refer to the Getting Started guide
Q. How do I add databases and catalogs to be monitored by DeltaOMS ?
You can add a database name to the DeltaOMS configuration table (by default called sourceconfig) using simple SQL INSERT statement.
Example:
INSERT INTO &amp;lt;omsCatalogName&amp;gt;.&amp;lt;omsDBName&amp;gt;.sourceconfig VALUES(&#39;&amp;lt;Database Name&amp;gt;&#39;,false)
You can add a single catalog or a pattern of catalogs to be monitored by DeltaOMS</description>
    </item>
    
    <item>
      <title>Pre-Requisites</title>
      <link>https://databrickslabs.github.io/delta-oms/getting_started/prerequisites/</link>
      <pubDate>Wed, 04 Aug 2021 14:25:26 -0400</pubDate>
      
      <guid>https://databrickslabs.github.io/delta-oms/getting_started/prerequisites/</guid>
      <description>Make sure you have the following available before proceeding :
Access to Databricks environment with access to Delta tables/databases defined on Unity Catalog and/or Hive Metastore Access to create and run notebooks on Unity Catalog and Non-Unity Catalog enabled clusters Ability to create Databricks job/workflows and run them on new cluster Proper access permissions to create catalog, schema, tables at the defined OMS external location Access to create libraries on your Databricks environment.</description>
    </item>
    
    <item>
      <title>Data Model</title>
      <link>https://databrickslabs.github.io/delta-oms/developer_guide/datamodels/</link>
      <pubDate>Wed, 04 Aug 2021 14:27:39 -0400</pubDate>
      
      <guid>https://databrickslabs.github.io/delta-oms/developer_guide/datamodels/</guid>
      <description>DeltaOMS collects and processes the operational metrics provided by Databricks Delta operations
DeltaOMS centralizes and organizes the data according to the following Data Model.</description>
    </item>
    
    <item>
      <title>Security</title>
      <link>https://databrickslabs.github.io/delta-oms/faq/security/</link>
      <pubDate>Wed, 04 Aug 2021 14:26:55 -0400</pubDate>
      
      <guid>https://databrickslabs.github.io/delta-oms/faq/security/</guid>
      <description>Q. Would I need to give permissions to all my data for this solution to work ?
DeltaOMS processes the Delta transaction logs implementing the Delta protocol to capture the different operational metrics. These logs are stored under the folder _delta_log alongside your data files. DeltaOMS only requires access to this _delta_log folder for the tracked data locations on a non-UC enabled cluster through Instance Profile
For more details on how DeltaOMS works please refer to the Developer Guide</description>
    </item>
    
    <item>
      <title>Setup</title>
      <link>https://databrickslabs.github.io/delta-oms/getting_started/setup/</link>
      <pubDate>Wed, 04 Aug 2021 14:25:26 -0400</pubDate>
      
      <guid>https://databrickslabs.github.io/delta-oms/getting_started/setup/</guid>
      <description>Initialize and Configure the DeltaOMS Database DeltaOMS is configured through Spark configurations with prefix spark.databricks.labs.deltaoms.
Refer to Additional Configurations section below for more details on the available configurations.
Follow the below steps to initialize the DeltaOMS centralized Database and tables.
Import and Open the DeltaOMS Setup notebook into your Databricks environment. You could also mount the DeltaOMS Github repo
Refer to the provided DeltaOMS workflow creation json template to create a workflow (using create api) for DeltaOMS initialization and configuration through the notebook Set the Spark configurations for initializing DeltaOMS on the defined cluster or modify the value of the variables for catalog name, schema name, external location URl and name as appropriate for your environment on the notebook</description>
    </item>
    
    <item>
      <title>Key Components</title>
      <link>https://databrickslabs.github.io/delta-oms/developer_guide/components/</link>
      <pubDate>Wed, 04 Aug 2021 14:27:39 -0400</pubDate>
      
      <guid>https://databrickslabs.github.io/delta-oms/developer_guide/components/</guid>
      <description>Initialization DeltaOMS provides the component com.databricks.labs.deltaoms.init.InitializeOMS for initializing
the centralized OMS schema and tables on the OMS catalog. The component creates the OMS schema at the EXTERNAL LOCATION specified by the configuration settings. Note: This process will delete all existing data in the specified location.
Refer to Additional Configurations for full configuration settings.
Configuration Once DeltaOMS has been initialized, and the input sources configured Source Config, the component provided by com.</description>
    </item>
    
    <item>
      <title>Execute</title>
      <link>https://databrickslabs.github.io/delta-oms/getting_started/execute/</link>
      <pubDate>Wed, 04 Aug 2021 14:25:26 -0400</pubDate>
      
      <guid>https://databrickslabs.github.io/delta-oms/getting_started/execute/</guid>
      <description>Execute the DeltaOMS Jobs You can run the jobs created in the previous step to ingest and process the delta transaction information for the configured tables into the centralized DeltaOMS schema.
For example, the OMSIngestion_* job(s) bring in the raw delta logs from the configured databases/tables and the OMSProcessing_* job processes the raw delta logs to format and enrich them for analytics.
For more advanced details on the working of these jobs please refer to the Developer Guide</description>
    </item>
    
    <item>
      <title>Analyze</title>
      <link>https://databrickslabs.github.io/delta-oms/getting_started/analyze/</link>
      <pubDate>Wed, 04 Aug 2021 14:25:26 -0400</pubDate>
      
      <guid>https://databrickslabs.github.io/delta-oms/getting_started/analyze/</guid>
      <description>Run analytics using sample notebooks You can run some sample analytics on the data from the OMS database using the provided notebook with appropriate modification for your use-case/environment
Modify the queries to reflect your configuration for the OMS Catalog Name , OMS DB Name and other table names (if applicable).
Executing this notebook will give you an idea on the type of analysis and data structure that can be utilized as part of the DeltaOMS.</description>
    </item>
    
    <item>
      <title>Additional Configuration</title>
      <link>https://databrickslabs.github.io/delta-oms/getting_started/additionalconfigurations/</link>
      <pubDate>Wed, 04 Aug 2021 14:25:26 -0400</pubDate>
      
      <guid>https://databrickslabs.github.io/delta-oms/getting_started/additionalconfigurations/</guid>
      <description>Spark Configuration DeltaOMS uses multiple Spark configurations to control its different components.
DeltaOMS Spark configuration (spark.conf) details :
Configuration Key Description Required Example Default Value Applies to components spark.databricks.labs.deltaoms.location.url Base location/path of the OMS catalog and schema on the Delta Lake. This is created as an EXTERNAL LOCATION on Unity Catalog (UC) Y s3:/delta-monitoring/deltaoms None All spark.databricks.labs.deltaoms.location.name Name of the UC EXTERNAL LOCATION for the OMS catalog and schema on the Delta Lake Y deltaoms-external-location None All spark.</description>
    </item>
    
  </channel>
</rss>
